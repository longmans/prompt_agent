#!/usr/bin/env python3
"""
Promptä¼˜åŒ–å™¨æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨å¤šAgentåä½œè¿›è¡Œpromptä¼˜åŒ–ï¼Œæ”¯æŒå¤šç§æ¨¡å‹
"""

import asyncio
import json
import os
from prompt_optimizer import PromptOptimizerWorkflow, PromptRequest


async def demo_software_development_gemini():
    """æ¼”ç¤ºä¸ºè½¯ä»¶å¼€å‘ä¼˜åŒ–prompt - ä½¿ç”¨Geminiæ¨¡å‹"""
    print("ğŸ”§ æ¼”ç¤ºï¼šè½¯ä»¶å¼€å‘promptä¼˜åŒ– - Geminiæ¨¡å‹")
    print("=" * 60)
    
    # åˆ›å»ºå·¥ä½œæµ
    workflow = PromptOptimizerWorkflow()
    
    # åˆ›å»ºè¯·æ±‚
    request = PromptRequest(
        role="software developers",
        basic_requirements="ç¼–å†™é«˜è´¨é‡ã€å¯ç»´æŠ¤çš„Pythonä»£ç ï¼ŒåŒ…æ‹¬å‡½æ•°ã€ç±»å’ŒAPIè®¾è®¡",
        examples=[  # å¯é€‰çš„ç¤ºä¾‹
            {
                "input": "Write a function to calculate fibonacci numbers",
                "output": "def fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)"
            },
            {
                "input": "Create a REST API endpoint",
                "output": "@app.route('/api/users', methods=['GET'])\ndef get_users():\n    return jsonify(users)"
            }
        ],
        additional_requirements="ä»£ç éœ€è¦åŒ…å«è¯¦ç»†çš„æ³¨é‡Šå’Œé”™è¯¯å¤„ç†",
        model_type="gemini"
    )
    
    print(f"ç›®æ ‡è§’è‰²: {request.role}")
    print(f"åŸºæœ¬è¦æ±‚: {request.basic_requirements}")
    print(f"æ¨¡å‹ç±»å‹: {request.model_type.upper()}")
    print(f"ç¤ºä¾‹æ•°é‡: {len(request.examples or [])}")
    print("å¼€å§‹ä¼˜åŒ–...")
    
    try:
        # æ‰§è¡Œä¼˜åŒ–
        result = await workflow.optimize_prompt(request)
        
        # æ˜¾ç¤ºç»“æœ
        print("\nâœ… ä¼˜åŒ–å®Œæˆï¼")
        print(f"\nğŸ“ ç”Ÿæˆçš„Prompt:")
        print("-" * 30)
        print(result.get('generated_prompt', 'N/A'))
        
        print(f"\nğŸ” è¯„ä¼°ç»“æœ:")
        print("-" * 30)
        for i, evaluation in enumerate(result.get('evaluations', []), 1):
            print(f"è¯„ä¼° {i}: {evaluation[:200]}...")
        
        print(f"\nğŸš€ æ”¹è¿›æ–¹æ¡ˆ ({len(result.get('alternative_prompts', []))}):")
        print("-" * 30)
        for i, alt in enumerate(result.get('alternative_prompts', []), 1):
            print(f"æ–¹æ¡ˆ {i}: {alt[:100]}...")
        
        print(f"\nğŸ’¡ æœ€ç»ˆæ¨è:")
        print("-" * 30)
        print(result.get('final_recommendation', 'N/A')[:200] + "...")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")


async def demo_software_development_openai():
    """æ¼”ç¤ºä¸ºè½¯ä»¶å¼€å‘ä¼˜åŒ–prompt - ä½¿ç”¨OpenAIæ¨¡å‹"""
    print("\n\nğŸ”§ æ¼”ç¤ºï¼šè½¯ä»¶å¼€å‘promptä¼˜åŒ– - OpenAIæ¨¡å‹")
    print("=" * 60)
    
    # æ£€æŸ¥OpenAI APIå¯†é’¥
    if not os.getenv('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') == 'your_openai_api_key_here':
        print("âš ï¸ è·³è¿‡OpenAIæ¼”ç¤ºï¼šæœªé…ç½®OPENAI_API_KEY")
        return
    
    # åˆ›å»ºå·¥ä½œæµ
    workflow = PromptOptimizerWorkflow()
    
    # åˆ›å»ºè¯·æ±‚
    request = PromptRequest(
        role="software developers",
        basic_requirements="ç¼–å†™å¥å£®ã€å¯æ‰©å±•çš„Pythonä»£ç ï¼Œé‡ç‚¹å…³æ³¨é”™è¯¯å¤„ç†å’Œæ–‡æ¡£",
        examples=[  # å¯é€‰çš„ç¤ºä¾‹
            {
                "input": json.dumps({
                    "function_name": "validate_email",
                    "input_type": "str",
                    "output_type": "bool",
                    "description": "éªŒè¯é‚®ç®±åœ°å€æ ¼å¼"
                }),
                "output": "def validate_email(email: str) -> bool:\n    \"\"\"éªŒè¯é‚®ç®±åœ°å€æ ¼å¼çš„æœ‰æ•ˆæ€§\n    Args:\n        email: è¦éªŒè¯çš„é‚®ç®±åœ°å€\n    Returns:\n        bool: é‚®ç®±æ ¼å¼æ˜¯å¦æœ‰æ•ˆ\n    \"\"\"\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return re.match(pattern, email) is not None"
            },
            {
                "input": json.dumps({
                    "class_name": "DatabaseConnection",
                    "host": "localhost",
                    "database": "mydb",
                    "username": "admin"
                }),
                "output": "class DatabaseConnection:\n    def __init__(self, host: str = 'localhost', database: str = 'mydb', username: str = 'admin'):\n        self.host = host\n        self.database = database\n        self.username = username\n        self.connection = None"
            }
        ],
        additional_requirements="ä»£ç éœ€è¦åŒ…å«å®Œæ•´çš„ç±»å‹æç¤ºå’Œå¼‚å¸¸å¤„ç†",
        model_type="openai"
    )
    
    print(f"ç›®æ ‡è§’è‰²: {request.role}")
    print(f"åŸºæœ¬è¦æ±‚: {request.basic_requirements}")
    print(f"æ¨¡å‹ç±»å‹: {request.model_type.upper()}")
    print(f"ç¤ºä¾‹æ•°é‡: {len(request.examples or [])}")
    print("å¼€å§‹ä¼˜åŒ–...")
    
    try:
        # æ‰§è¡Œä¼˜åŒ–
        result = await workflow.optimize_prompt(request)
        
        # æ˜¾ç¤ºç»“æœ
        print("\nâœ… ä¼˜åŒ–å®Œæˆï¼")
        print(f"ç”Ÿæˆçš„prompté•¿åº¦: {len(result.get('generated_prompt', ''))} å­—ç¬¦")
        print(f"ç”Ÿæˆçš„prompt: {result.get('generated_prompt', '')}")
        print(f"è¯„ä¼°æ•°é‡: {len(result.get('evaluations', []))}")
        print(f"æ”¹è¿›æ–¹æ¡ˆæ•°é‡: {len(result.get('alternative_prompts', []))}")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")


async def demo_customer_support():
    """æ¼”ç¤ºä¸ºå®¢æœä¼˜åŒ–prompt"""
    print("\n\nğŸ“ æ¼”ç¤ºï¼šå®¢æœå¯¹è¯promptä¼˜åŒ– - Geminiæ¨¡å‹")
    print("=" * 60)
    
    workflow = PromptOptimizerWorkflow()
    
    request = PromptRequest(
        role="customer support representatives",
        basic_requirements="æä¾›ä¸“ä¸šã€æœ‰åŒç†å¿ƒçš„å®¢æˆ·æœåŠ¡ï¼Œå¿«é€Ÿè§£å†³å®¢æˆ·é—®é¢˜",
        examples=[  # å¯é€‰çš„ç¤ºä¾‹
            {
                "input": "Customer complains about delayed delivery",
                "output": "I sincerely apologize for the delay. Let me check your order status and provide an update."
            },
            {
                "input": "Customer asks for refund",
                "output": "I understand your concern. I'd be happy to help with the refund process."
            }
        ],
        additional_requirements="ä¿æŒç§¯æå‹å¥½çš„è¯­æ°”ï¼Œæä¾›æ˜ç¡®çš„è§£å†³æ–¹æ¡ˆ",
        model_type="openai"
    )
    
    print(f"ç›®æ ‡è§’è‰²: {request.role}")
    print(f"åŸºæœ¬è¦æ±‚: {request.basic_requirements}")
    print(f"æ¨¡å‹ç±»å‹: {request.model_type.upper()}")
    print("å¼€å§‹ä¼˜åŒ–...")
    
    try:
        result = await workflow.optimize_prompt(request)
        print("âœ… å®¢æœpromptä¼˜åŒ–å®Œæˆï¼")
        print(f"ç”Ÿæˆçš„prompté•¿åº¦: {len(result.get('generated_prompt', ''))} å­—ç¬¦")
        print(f"è¯„ä¼°æ•°é‡: {len(result.get('evaluations', []))}")
        print(f"æ”¹è¿›æ–¹æ¡ˆæ•°é‡: {len(result.get('alternative_prompts', []))}")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")


async def demo_content_creation():
    """æ¼”ç¤ºä¸ºå†…å®¹åˆ›ä½œä¼˜åŒ–prompt"""
    print("\n\nâœï¸ æ¼”ç¤ºï¼šå†…å®¹åˆ›ä½œpromptä¼˜åŒ– - OpenAIæ¨¡å‹")
    print("=" * 60)
    
    workflow = PromptOptimizerWorkflow()
    
    request = PromptRequest(
        role="content creators",
        basic_requirements="åˆ›ä½œå¼•äººå…¥èƒœã€ç»“æ„æ¸…æ™°çš„å†…å®¹ï¼ŒåŒ…æ‹¬åšå®¢æ–‡ç« å’Œç¤¾äº¤åª’ä½“å¸–å­",
        examples=[  # å¯é€‰çš„ç¤ºä¾‹
            {
                "input": json.dumps({
                    "topic": "AI trends",
                    "target_audience": "tech professionals",
                    "tone": "professional",
                    "word_count": "1000"
                }),
                "output": "# The Future of AI: 5 Trends That Will Shape 2024\n\nArtificial Intelligence continues to evolve rapidly, transforming industries and reshaping how we work..."
            },
            {
                "input": json.dumps({
                    "topic": "sustainability",
                    "target_audience": "general public",
                    "tone": "casual",
                    "word_count": "200"
                }),
                "output": "ğŸŒ± Small changes, BIG impact! Here are 3 easy sustainability tips that anyone can follow to help protect our planet..."
            }
        ],
        additional_requirements="å†…å®¹éœ€è¦åŒ…å«å¸å¼•äººçš„æ ‡é¢˜å’Œæ¸…æ™°çš„è¡ŒåŠ¨å·å¬",
        model_type="openai"
    )
    
    print(f"ç›®æ ‡è§’è‰²: {request.role}")
    print(f"åŸºæœ¬è¦æ±‚: {request.basic_requirements}")
    print(f"æ¨¡å‹ç±»å‹: {request.model_type.upper()}")
    print("å¼€å§‹ä¼˜åŒ–...")
    
    try:
        result = await workflow.optimize_prompt(request)
        print("âœ… å†…å®¹åˆ›ä½œpromptä¼˜åŒ–å®Œæˆï¼")
        
        # æ˜¾ç¤ºç®€åŒ–çš„ç»“æœ
        print(f"\nğŸ“Š ä¼˜åŒ–ç»“æœæ‘˜è¦:")
        print(f"- æ¨¡å‹ç±»å‹: {result.get('model_type', 'unknown').upper()}")
        print(f"- åŸå§‹ç¤ºä¾‹: {len(result.get('original_examples', []))}")
        print(f"- ç”Ÿæˆprompté•¿åº¦: {len(result.get('generated_prompt', ''))} å­—ç¬¦")
        print(f"- è¯„ä¼°æŠ¥å‘Š: {len(result.get('evaluations', []))} ä»½")
        print(f"- æ”¹è¿›æ–¹æ¡ˆ: {len(result.get('alternative_prompts', []))} ä¸ª")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")


async def demo_no_examples():
    """æ¼”ç¤ºæ— ç¤ºä¾‹çš„promptä¼˜åŒ–"""
    print("\n\nğŸ¯ æ¼”ç¤ºï¼šæ— ç¤ºä¾‹çš„promptä¼˜åŒ– - OpenAIæ¨¡å‹")
    print("=" * 60)
    
    # æ£€æŸ¥OpenAI APIå¯†é’¥
    if not os.getenv('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') == 'your_openai_api_key_here':
        print("âš ï¸ è·³è¿‡OpenAIæ¼”ç¤ºï¼šæœªé…ç½®OPENAI_API_KEY")
        return
    
    workflow = PromptOptimizerWorkflow()
    
    request = PromptRequest(
        role="data scientists",
        basic_requirements="è¿›è¡Œæ•°æ®åˆ†æå’Œå¯è§†åŒ–ï¼Œç”Ÿæˆæ¸…æ™°çš„è§è§£æŠ¥å‘Š",
        examples=[],  # ä¸æä¾›ç¤ºä¾‹
        additional_requirements="æŠ¥å‘Šéœ€è¦åŒ…å«æ•°æ®æ¥æºã€æ–¹æ³•è®ºå’Œå…³é”®å‘ç°",
        model_type="openai"
    )
    
    print(f"ç›®æ ‡è§’è‰²: {request.role}")
    print(f"åŸºæœ¬è¦æ±‚: {request.basic_requirements}")
    print(f"æ¨¡å‹ç±»å‹: {request.model_type.upper()}")
    print("å¼€å§‹ä¼˜åŒ–...")
    
    try:
        result = await workflow.optimize_prompt(request)
        print("âœ… æ— ç¤ºä¾‹promptä¼˜åŒ–å®Œæˆï¼")
        
        # æ˜¾ç¤ºç®€åŒ–çš„ç»“æœ
        print(f"\nğŸ“Š ä¼˜åŒ–ç»“æœæ‘˜è¦:")
        print(f"- ç”Ÿæˆprompté•¿åº¦: {len(result.get('generated_prompt', ''))} å­—ç¬¦")
        print(f"- è¯„ä¼°æŠ¥å‘Š: {len(result.get('evaluations', []))} ä»½")
        print(f"- æ”¹è¿›æ–¹æ¡ˆ: {len(result.get('alternative_prompts', []))} ä¸ª")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ å¯åŠ¨Promptä¼˜åŒ–å™¨æ¼”ç¤º...")
    print("\nğŸ’¡ æœ¬æ¼”ç¤ºå°†å±•ç¤ºä¸åŒåœºæ™¯ä¸‹çš„promptä¼˜åŒ–è¿‡ç¨‹")
    print("åŒ…æ‹¬è½¯ä»¶å¼€å‘ã€å®¢æœå¯¹è¯ã€å†…å®¹åˆ›ä½œç­‰åœºæ™¯")
    print("åŒæ—¶æ¼”ç¤ºä¸åŒæ¨¡å‹ï¼ˆGemini/OpenAIï¼‰çš„æ•ˆæœ")
    
    # è¿è¡Œæ‰€æœ‰æ¼”ç¤º
    #await demo_software_development_gemini()
    await demo_software_development_openai()
    await demo_customer_support()
    await demo_content_creation()
    await demo_no_examples()  # æ–°å¢ï¼šæ¼”ç¤ºæ— ç¤ºä¾‹çš„æƒ…å†µ
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ“ æ€»ç»“ï¼š")
    print("1. æ”¯æŒå¤šç§ç”¨æˆ·è§’è‰²å’Œåœºæ™¯")
    print("2. å¯ä»¥ä½¿ç”¨ä¸åŒçš„æ¨¡å‹")
    print("3. ç¤ºä¾‹æ˜¯å¯é€‰çš„ï¼ŒåŸºæœ¬è¦æ±‚æ˜¯å¿…éœ€çš„")
    print("4. æä¾›è¯¦ç»†çš„è¯„ä¼°å’Œæ”¹è¿›å»ºè®®")
    print("5. æ”¯æŒæµå¼è¾“å‡ºå’Œæ ¼å¼åŒ–å±•ç¤º")

if __name__ == "__main__":
    asyncio.run(main()) 