#!/usr/bin/env python3
"""
åŸºäºGradioçš„Promptä¼˜åŒ–å™¨Webç•Œé¢
æ”¯æŒæµå¼è¾“å‡ºã€æ‰‹åŠ¨éªŒè¯å’Œå˜é‡ç¼–è¾‘
"""

import gradio as gr
import asyncio
import json
import re
import os
import logging
from typing import Dict, List, Any, Iterator, Tuple, Optional
from datetime import datetime
from prompt_optimizer import PromptOptimizerWorkflow, PromptRequest, ModelFactory
from dotenv import load_dotenv

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class SessionState:
    """ä¼šè¯çŠ¶æ€ç®¡ç†ç±»ï¼Œé¿å…ä½¿ç”¨å…¨å±€å˜é‡"""
    
    def __init__(self):
        self.current_result: Dict[str, Any] = {}
        self.last_update: Optional[datetime] = None
        self.optimization_history: List[Dict[str, Any]] = []
    
    def update_result(self, result: Dict[str, Any]) -> None:
        """æ›´æ–°å½“å‰ç»“æœ"""
        self.current_result = result
        self.last_update = datetime.now()
        logger.info(f"ç»“æœå·²æ›´æ–°: {result.get('role', 'Unknown')}")
    
    def get_current_prompt(self) -> str:
        """è·å–å½“å‰ç”Ÿæˆçš„prompt"""
        return self.current_result.get('final_recommendation', 
                                     self.current_result.get('generated_prompt', ''))
    
    def add_to_history(self, result: Dict[str, Any]) -> None:
        """æ·»åŠ åˆ°ä¼˜åŒ–å†å²"""
        if result and result.get('step') == 'completed':
            self.optimization_history.append({
                **result,
                'timestamp': datetime.now().isoformat()
            })
            logger.info(f"æ·»åŠ åˆ°å†å²è®°å½•ï¼Œå½“å‰å†å²æ•°é‡: {len(self.optimization_history)}")

# åˆ›å»ºä¼šè¯çŠ¶æ€å®ä¾‹
session_state = SessionState()

class StreamingOptimizer:
    """æµå¼å¤„ç†Promptä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.workflow: Optional[PromptOptimizerWorkflow] = None
        self.current_step: str = ""
        
    async def optimize_with_streaming(
        self,
        role: str,
        basic_requirements: str,
        examples: List[Dict[str, str]],
        additional_requirements: str,
        model_type: str
    ) -> Iterator[Tuple[str, str, str]]:
        """æ‰§è¡Œä¼˜åŒ–å¹¶æµå¼è¿”å›ç»“æœ"""
        logger.info(f"å¼€å§‹ä¼˜åŒ–æµç¨‹: role={role}, model={model_type}")
        
        try:
            # è¾“å…¥é¢„å¤„ç†å’ŒéªŒè¯
            role = role.strip()
            basic_requirements = basic_requirements.strip()
            additional_requirements = additional_requirements.strip()
            model_type = model_type.lower()
            
            if not role:
                raise ValueError("è§’è‰²ä¸èƒ½ä¸ºç©º")
            if not basic_requirements:
                raise ValueError("åŸºæœ¬è¦æ±‚ä¸èƒ½ä¸ºç©º")
            
            # åˆ›å»ºè¯·æ±‚
            request = PromptRequest(
                role=role,
                basic_requirements=basic_requirements,
                examples=examples,
                additional_requirements=additional_requirements,
                model_type=model_type
            )
            
            # åˆå§‹åŒ–å·¥ä½œæµ
            yield "ğŸš€ å¼€å§‹", f"æ­£åœ¨åˆå§‹åŒ– {model_type.upper()} æ¨¡å‹...", ""
            logger.info(f"åˆå§‹åŒ–å·¥ä½œæµï¼Œæ¨¡å‹ç±»å‹: {model_type}")
            
            try:
                self.workflow = PromptOptimizerWorkflow()
            except Exception as e:
                logger.error(f"å·¥ä½œæµåˆå§‹åŒ–å¤±è´¥: {str(e)}")
                raise ConnectionError(f"æ— æ³•åˆå§‹åŒ–{model_type}æ¨¡å‹ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®")
            
            yield "ğŸ“‹ éªŒè¯", "æ­£åœ¨éªŒè¯è¾“å…¥å‚æ•°...", ""
            
            # åˆ›å»ºåˆå§‹çŠ¶æ€
            from prompt_optimizer import PromptOptimizerState
            initial_state = PromptOptimizerState(
                messages=[],
                role=request.role,
                basic_requirements=request.basic_requirements,
                examples=request.examples or [],
                current_prompt="",
                evaluations=[],
                alternative_prompts=[],
                final_prompt="",
                step="started",
                model_type=request.model_type
            )
            
            # é€æ­¥æ‰§è¡Œå·¥ä½œæµ
            yield "ğŸ“– ç”ŸæˆæŒ‡å¯¼", "æ­£åœ¨ç”Ÿæˆpromptå·¥ç¨‹æŒ‡å¯¼...", ""
            try:
                guide_result = await self.workflow._generate_guide_node(initial_state)
                initial_state.update(guide_result)
                logger.debug("promptå·¥ç¨‹æŒ‡å¯¼ç”Ÿæˆå®Œæˆ")
            except Exception as e:
                logger.warning(f"ç”ŸæˆæŒ‡å¯¼å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {str(e)}")
            
            yield "âœï¸ ç”ŸæˆPrompt", "æ­£åœ¨æ ¹æ®è§’è‰²å’Œè¦æ±‚ç”Ÿæˆåˆå§‹prompt...", ""
            try:
                prompt_result = await self.workflow._generate_prompt_node(initial_state)
                initial_state.update(prompt_result)
                generated_prompt = initial_state.get('current_prompt', '')
                logger.debug(f"åˆå§‹promptç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(generated_prompt)}")
            except Exception as e:
                logger.error(f"ç”Ÿæˆpromptå¤±è´¥: {str(e)}")
                raise RuntimeError("ç”Ÿæˆpromptå¤±è´¥ï¼Œè¯·é‡è¯•")
            
            yield "ğŸ“Š è¯„ä¼°å‡†å¤‡", "æ­£åœ¨å‡†å¤‡è¯„ä¼°æ¡†æ¶...", ""
            try:
                eval_guide_result = await self.workflow._generate_eval_guide_node(initial_state)
                initial_state.update(eval_guide_result)
            except Exception as e:
                logger.warning(f"è¯„ä¼°æ¡†æ¶å‡†å¤‡å¤±è´¥: {str(e)}")
            
            yield "ğŸ” æ‰§è¡Œè¯„ä¼°", "æ­£åœ¨è¯„ä¼°promptè´¨é‡...", ""
            try:
                evaluation_result = await self.workflow._evaluate_prompt_node(initial_state)
                initial_state.update(evaluation_result)
                logger.debug("promptè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logger.warning(f"promptè¯„ä¼°å¤±è´¥: {str(e)}")
            
            yield "ğŸš€ ç”Ÿæˆæ”¹è¿›", "æ­£åœ¨ç”Ÿæˆæ”¹è¿›æ–¹æ¡ˆ...", ""
            try:
                improvement_result = await self.workflow._improve_prompts_node(initial_state)
                initial_state.update(improvement_result)
                logger.debug(f"ç”Ÿæˆäº† {len(initial_state.get('alternative_prompts', []))} ä¸ªæ”¹è¿›æ–¹æ¡ˆ")
            except Exception as e:
                logger.warning(f"ç”Ÿæˆæ”¹è¿›æ–¹æ¡ˆå¤±è´¥: {str(e)}")
            
            yield "ğŸ¯ æœ€ç»ˆç¡®å®š", "æ­£åœ¨é€‰æ‹©æœ€ä½³prompt...", ""
            try:
                final_result = await self.workflow._finalize_node(initial_state)
                initial_state.update(final_result)
            except Exception as e:
                logger.error(f"æœ€ç»ˆç¡®å®šå¤±è´¥: {str(e)}")
                raise RuntimeError("æœ€ç»ˆç¡®å®šå¤±è´¥ï¼Œè¯·é‡è¯•")
            
            # æ•´ç†æœ€ç»ˆç»“æœ
            result = {
                "role": initial_state["role"],
                "basic_requirements": initial_state["basic_requirements"],
                "model_type": initial_state["model_type"],
                "original_examples": initial_state["examples"],
                "generated_prompt": initial_state.get("current_prompt", ""),
                "evaluations": initial_state.get("evaluations", []),
                "alternative_prompts": initial_state.get("alternative_prompts", []),
                "final_recommendation": initial_state.get("final_prompt", ""),
                "step": initial_state.get("step", "completed")
            }
            
            # æ›´æ–°ä¼šè¯çŠ¶æ€
            session_state.update_result(result)
            session_state.add_to_history(result)
            
            # æ ¼å¼åŒ–æœ€ç»ˆè¾“å‡º
            final_output = self._format_final_result(result)
            
            yield "âœ… å®Œæˆ", "Promptä¼˜åŒ–å·²å®Œæˆï¼", final_output
            logger.info("ä¼˜åŒ–æµç¨‹æˆåŠŸå®Œæˆ")
            
        except ValueError as e:
            error_msg = f"è¾“å…¥éªŒè¯é”™è¯¯: {str(e)}"
            logger.warning(error_msg)
            yield "âŒ è¾“å…¥é”™è¯¯", error_msg, ""
        except ConnectionError as e:
            error_msg = f"è¿æ¥é”™è¯¯: {str(e)}"
            logger.error(error_msg)
            yield "âŒ è¿æ¥é”™è¯¯", error_msg, ""
        except RuntimeError as e:
            error_msg = f"è¿è¡Œæ—¶é”™è¯¯: {str(e)}"
            logger.error(error_msg)
            yield "âŒ è¿è¡Œé”™è¯¯", error_msg, ""
        except Exception as e:
            error_msg = f"æœªçŸ¥é”™è¯¯: {str(e)}"
            logger.error(error_msg, exc_info=True)
            yield "âŒ ç³»ç»Ÿé”™è¯¯", error_msg, ""
    
    def _parse_examples(self, examples_text: str) -> List[Dict[str, str]]:
        """è§£æç¤ºä¾‹æ–‡æœ¬ï¼Œå¢å¼ºå¥å£®æ€§"""
        if not examples_text or not examples_text.strip():
            logger.debug("æœªæä¾›ç¤ºä¾‹æ–‡æœ¬")
            return []
        
        # è§„èŒƒåŒ–è¾“å…¥
        examples_text = examples_text.replace('\r\n', '\n').strip()
        
        try:
            if examples_text.startswith('['):
                # JSONæ•°ç»„æ ¼å¼
                examples = json.loads(examples_text)
                if not isinstance(examples, list):
                    raise ValueError("ç¤ºä¾‹å¿…é¡»æ˜¯æ•°ç»„æ ¼å¼")
                
                # éªŒè¯å’Œè§„èŒƒåŒ–æ¯ä¸ªç¤ºä¾‹
                normalized_examples = []
                for i, example in enumerate(examples):
                    if not isinstance(example, dict):
                        raise ValueError(f"ç¤ºä¾‹ {i+1} å¿…é¡»æ˜¯å¯¹è±¡æ ¼å¼")
                    if 'input' not in example or 'output' not in example:
                        raise ValueError(f"ç¤ºä¾‹ {i+1} å¿…é¡»åŒ…å« 'input' å’Œ 'output' å­—æ®µ")
                    
                    # ç¡®ä¿inputå­—æ®µæ˜¯JSONå­—ç¬¦ä¸²
                    if isinstance(example['input'], dict):
                        example['input'] = json.dumps(example['input'], ensure_ascii=False)
                    elif not isinstance(example['input'], str):
                        example['input'] = str(example['input'])
                    
                    # ç¡®ä¿outputæ˜¯å­—ç¬¦ä¸²
                    if not isinstance(example['output'], str):
                        example['output'] = str(example['output'])
                    
                    normalized_examples.append(example)
                
                logger.info(f"æˆåŠŸè§£æJSONæ ¼å¼ç¤ºä¾‹ï¼Œæ•°é‡: {len(normalized_examples)}")
                return normalized_examples
            else:
                # ç®€å•æ–‡æœ¬æ ¼å¼ï¼Œè½¬æ¢ä¸ºJSON
                examples = []
                current_input = {}
                current_output = ""
                mode = None
                
                # åˆ†å‰²æˆè¡Œå¹¶ç§»é™¤ç©ºè¡Œ
                lines = [line.strip() for line in examples_text.split('\n') if line.strip()]
                
                for line in lines:
                    line_lower = line.lower()
                    if line_lower.startswith('input:'):
                        # ä¿å­˜ä¸Šä¸€ä¸ªç¤ºä¾‹
                        if current_input and current_output:
                            examples.append({
                                "input": json.dumps(current_input, ensure_ascii=False), 
                                "output": current_output.strip()
                            })
                        current_input = {}
                        current_output = ""
                        mode = "input"
                    elif line_lower.startswith('output:'):
                        current_output = line[7:].strip()
                        mode = "output"
                    elif line and mode == "input":
                        # å°è¯•è§£ækey=valueæ ¼å¼
                        if '=' in line:
                            key, value = line.split('=', 1)
                            current_input[key.strip()] = value.strip()
                        else:
                            # å¦‚æœä¸æ˜¯key=valueæ ¼å¼ï¼Œä½œä¸ºçº¯æ–‡æœ¬å¤„ç†
                            current_input['text'] = current_input.get('text', '') + ' ' + line
                    elif line and mode == "output":
                        current_output += "\n" + line
                
                # æ·»åŠ æœ€åä¸€ç»„ç¤ºä¾‹
                if current_input and current_output:
                    examples.append({
                        "input": json.dumps(current_input, ensure_ascii=False), 
                        "output": current_output.strip()
                    })
                
                if not examples:
                    logger.warning("æœªèƒ½ä»æ–‡æœ¬ä¸­è§£æå‡ºæœ‰æ•ˆç¤ºä¾‹")
                    return []
                
                logger.info(f"æˆåŠŸè§£ææ–‡æœ¬æ ¼å¼ç¤ºä¾‹ï¼Œæ•°é‡: {len(examples)}")
                return examples
                
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æé”™è¯¯: {str(e)}")
            raise ValueError(f"ç¤ºä¾‹æ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥JSONè¯­æ³•: {str(e)}")
        except Exception as e:
            logger.error(f"è§£æç¤ºä¾‹æ—¶å‡ºé”™: {str(e)}")
            raise ValueError(f"è§£æç¤ºä¾‹å¤±è´¥: {str(e)}")
    
    def _format_final_result(self, result: Dict) -> str:
        """æ ¼å¼åŒ–æœ€ç»ˆç»“æœ"""
        try:
            output = f"""
# ğŸ‰ Promptä¼˜åŒ–ç»“æœ

## ğŸ’¡ æœ€ç»ˆæ¨èçš„Prompt
```
{result.get('final_recommendation', 'N/A')}
```

## ğŸ“Š åŸºæœ¬ä¿¡æ¯
- **ç›®æ ‡è§’è‰²**: {result.get('role', 'N/A')}
- **åŸºæœ¬è¦æ±‚**: {result.get('basic_requirements', 'N/A')}
- **ä½¿ç”¨æ¨¡å‹**: {result.get('model_type', 'unknown').upper()}
- **ç¤ºä¾‹æ•°é‡**: {len(result.get('original_examples', []))}
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“ ç”Ÿæˆçš„ä¸»è¦Prompt
```
{result.get('generated_prompt', 'N/A')}
```

## ğŸ” è¯„ä¼°ç»“æœ
{result.get('evaluations', ['N/A'])[0][:500] + ('...' if len(result.get('evaluations', [''])[0]) > 500 else '') if result.get('evaluations') else 'N/A'}

## ğŸš€ æ”¹è¿›æ–¹æ¡ˆ ({len(result.get('alternative_prompts', []))}) ä¸ª)
"""
            
            for i, alt_prompt in enumerate(result.get('alternative_prompts', [])[:3], 1):
                output += f"""
### æ–¹æ¡ˆ {i}
```
{alt_prompt[:200]}{'...' if len(alt_prompt) > 200 else ''}
```
"""
            
            return output
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–ç»“æœæ—¶å‡ºé”™: {str(e)}")
            return f"æ ¼å¼åŒ–ç»“æœæ—¶å‡ºç°é”™è¯¯: {str(e)}"

# å…¨å±€ä¼˜åŒ–å™¨å®ä¾‹
optimizer = StreamingOptimizer()

def validate_inputs(role: str, basic_requirements: str, examples: str, model_type: str) -> str:
    """éªŒè¯è¾“å…¥å‚æ•°ï¼Œå¢å¼ºå¥å£®æ€§"""
    logger.debug(f"éªŒè¯è¾“å…¥: role={bool(role.strip())}, basic_requirements={bool(basic_requirements.strip())}, examples={bool(examples.strip())}, model={model_type}")
    
    # éªŒè¯å¿…éœ€å­—æ®µ
    if not role or not role.strip():
        return "âŒ è¯·å¡«å†™ç›®æ ‡è§’è‰²"
    
    if not basic_requirements or not basic_requirements.strip():
        return "âŒ è¯·å¡«å†™åŸºæœ¬è¦æ±‚"
    
    # éªŒè¯æ¨¡å‹ç±»å‹
    if model_type.lower() not in ["gemini", "openai"]:
        return f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}ã€‚æ”¯æŒçš„ç±»å‹: gemini, openai"
    
    # å¦‚æœæä¾›äº†ç¤ºä¾‹ï¼ŒéªŒè¯æ ¼å¼
    if examples and examples.strip():
        try:
            # å°è¯•ä½¿ç”¨ StreamingOptimizer çš„è§£ææ–¹æ³•
            optimizer_temp = StreamingOptimizer()
            parsed_examples = optimizer_temp._parse_examples(examples)
            
            if parsed_examples:
                logger.info(f"ç¤ºä¾‹éªŒè¯æˆåŠŸï¼Œæ•°é‡: {len(parsed_examples)}")
                
                # éªŒè¯å­—æ®µåä¸€è‡´æ€§ï¼ˆå’Œ prompt_optimizer.py ä¿æŒä¸€è‡´ï¼‰
                first_example_fields = None
                for i, example in enumerate(parsed_examples, 1):
                    try:
                        input_data = json.loads(example['input']) if isinstance(example['input'], str) else example['input']
                        if not isinstance(input_data, dict):
                            return f"âŒ ç¤ºä¾‹ {i} çš„ 'input' å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONå¯¹è±¡"
                        
                        # è·å–å½“å‰ç¤ºä¾‹çš„å­—æ®µåé›†åˆ
                        current_fields = set(input_data.keys())
                        
                        # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªç¤ºä¾‹ï¼Œä¿å­˜å…¶å­—æ®µå
                        if first_example_fields is None:
                            first_example_fields = current_fields
                        # å¦åˆ™æ¯”è¾ƒå­—æ®µåæ˜¯å¦ä¸€è‡´
                        elif current_fields != first_example_fields:
                            # æ‰¾å‡ºä¸ä¸€è‡´çš„å­—æ®µ
                            missing_fields = first_example_fields - current_fields
                            extra_fields = current_fields - first_example_fields
                            error_msg = f"âŒ ç¤ºä¾‹ {i} çš„å­—æ®µåä¸ç¬¬ä¸€ä¸ªç¤ºä¾‹ä¸ä¸€è‡´ã€‚"
                            if missing_fields:
                                error_msg += f"\nç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}"
                            if extra_fields:
                                error_msg += f"\nå¤šä½™å­—æ®µ: {', '.join(extra_fields)}"
                            return error_msg
                    except json.JSONDecodeError:
                        return f"âŒ ç¤ºä¾‹ {i} çš„ 'input' å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼"
                        
        except ValueError as e:
            return f"âŒ ç¤ºä¾‹æ ¼å¼é”™è¯¯: {str(e)}"
        except Exception as e:
            logger.error(f"ç¤ºä¾‹éªŒè¯æ—¶å‡ºé”™: {str(e)}")
            return f"âŒ ç¤ºä¾‹éªŒè¯å¤±è´¥: {str(e)}"
    
    # éªŒè¯APIå¯†é’¥
    try:
        if model_type.lower() == "gemini":
            api_key = os.getenv('GOOGLE_API_KEY')
            if not api_key or api_key == 'your_google_api_key_here':
                return "âŒ è¯·å…ˆé…ç½®GOOGLE_API_KEYç¯å¢ƒå˜é‡"
        elif model_type.lower() == "openai":
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key or api_key == 'your_openai_api_key_here':
                return "âŒ è¯·å…ˆé…ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡"
    except Exception as e:
        logger.error(f"APIå¯†é’¥éªŒè¯æ—¶å‡ºé”™: {str(e)}")
        return f"âŒ APIå¯†é’¥éªŒè¯å¤±è´¥: {str(e)}"
    
    logger.info("è¾“å…¥éªŒè¯é€šè¿‡")
    return "âœ… è¾“å…¥éªŒè¯é€šè¿‡"

async def run_optimization(
    role: str,
    basic_requirements: str,
    examples: str,
    additional_requirements: str,
    model_type: str,
    progress=gr.Progress()
):
    """è¿è¡Œä¼˜åŒ–å¹¶æ›´æ–°è¿›åº¦ï¼Œå¢å¼ºé”™è¯¯å¤„ç†"""
    
    # éªŒè¯è¾“å…¥
    validation_result = validate_inputs(role, basic_requirements, examples, model_type)
    if validation_result.startswith("âŒ"):
        logger.warning(f"è¾“å…¥éªŒè¯å¤±è´¥: {validation_result}")
        yield validation_result, "", gr.update(visible=False), gr.update(visible=False)
        return
    
    status_output = ""
    final_output = ""
    
    progress(0, desc="å¼€å§‹åˆå§‹åŒ–...")
    logger.info(f"å¼€å§‹Promptä¼˜åŒ–æµç¨‹: role={role}, model={model_type}")
    
    try:
        # è§£æç¤ºä¾‹ï¼ˆå¦‚æœæœ‰ï¼‰
        examples_list = []
        if examples.strip():
            try:
                examples_list = optimizer._parse_examples(examples)
                logger.info(f"æˆåŠŸè§£æç¤ºä¾‹ï¼Œæ•°é‡: {len(examples_list)}")
            except Exception as e:
                logger.error(f"è§£æç¤ºä¾‹å¤±è´¥: {str(e)}")
                yield f"âŒ è§£æç¤ºä¾‹å¤±è´¥: {str(e)}", "", gr.update(visible=False), gr.update(visible=False)
                return
        
        # æ‰§è¡Œæµå¼ä¼˜åŒ–
        async for step, status, output in optimizer.optimize_with_streaming(
            role=role,
            basic_requirements=basic_requirements,
            examples=examples_list,
            additional_requirements=additional_requirements,
            model_type=model_type
        ):
            # æ›´æ–°çŠ¶æ€è¾“å‡º
            timestamp = datetime.now().strftime('%H:%M:%S')
            status_output += f"[{timestamp}] {step}: {status}\n"
            
            if output:
                final_output = output
                logger.info("ä¼˜åŒ–ç»“æœå·²ç”Ÿæˆ")
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_value = 0.1
            if "éªŒè¯" in step:
                progress_value = 0.2
            elif "ç”ŸæˆæŒ‡å¯¼" in step:
                progress_value = 0.3
            elif "ç”ŸæˆPrompt" in step:
                progress_value = 0.5
            elif "è¯„ä¼°å‡†å¤‡" in step:
                progress_value = 0.6
            elif "æ‰§è¡Œè¯„ä¼°" in step:
                progress_value = 0.7
            elif "ç”Ÿæˆæ”¹è¿›" in step:
                progress_value = 0.8
            elif "æœ€ç»ˆç¡®å®š" in step:
                progress_value = 0.9
            elif "å®Œæˆ" in step:
                progress_value = 1.0
                
            progress(progress_value, desc=status)
            
            # è¿”å›æ›´æ–°çš„UIçŠ¶æ€
            show_results = bool(final_output)
            yield status_output, final_output, gr.update(visible=show_results), gr.update(visible=show_results)
        
        logger.info("ä¼˜åŒ–æµç¨‹å®Œæˆ")
        
    except Exception as e:
        error_msg = f"ä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ºç°æœªçŸ¥é”™è¯¯: {str(e)}"
        logger.error(error_msg, exc_info=True)
        yield error_msg, "", gr.update(visible=False), gr.update(visible=False)

def get_current_prompt() -> str:
    """è·å–å½“å‰ç”Ÿæˆçš„promptï¼Œä½¿ç”¨ä¼šè¯çŠ¶æ€"""
    try:
        return session_state.get_current_prompt()
    except Exception as e:
        logger.error(f"è·å–å½“å‰promptå¤±è´¥: {str(e)}")
        return ""

def extract_variables(prompt: str) -> List[str]:
    """æå–promptä¸­çš„å˜é‡ï¼ˆå¦‚{name}, {topic}ç­‰ï¼‰ï¼Œå¢å¼ºå¥å£®æ€§"""
    try:
        if not prompt or not isinstance(prompt, str):
            return []
        variables = re.findall(r'\{([^}]+)\}', prompt)
        unique_variables = list(set(variables))
        logger.debug(f"æå–åˆ°å˜é‡: {unique_variables}")
        return unique_variables
    except Exception as e:
        logger.error(f"æå–å˜é‡æ—¶å‡ºé”™: {str(e)}")
        return []

def validate_prompt(prompt: str, variables: str) -> str:
    """éªŒè¯promptå¹¶æ›¿æ¢å˜é‡ï¼Œå¢å¼ºé”™è¯¯å¤„ç†"""
    try:
        if not prompt or not isinstance(prompt, str):
            return "âŒ promptä¸èƒ½ä¸ºç©º"
            
        # è§£æå˜é‡
        if variables and variables.strip():
            var_dict = {}
            try:
                for line in variables.strip().split('\n'):
                    line = line.strip()
                    if '=' in line:
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip()
                        if key and value:  # ç¡®ä¿é”®å’Œå€¼éƒ½ä¸ä¸ºç©º
                            var_dict[key] = value
                        else:
                            return f"âŒ å˜é‡å®šä¹‰æ ¼å¼é”™è¯¯: '{line}' (é”®æˆ–å€¼ä¸èƒ½ä¸ºç©º)"
                    elif line:  # å¿½ç•¥ç©ºè¡Œ
                        return f"âŒ å˜é‡å®šä¹‰æ ¼å¼é”™è¯¯: '{line}' (åº”ä½¿ç”¨ key=value æ ¼å¼)"
            except Exception as e:
                return f"âŒ è§£æå˜é‡å®šä¹‰æ—¶å‡ºé”™: {str(e)}"
            
            # æ›¿æ¢å˜é‡
            test_prompt = prompt
            for key, value in var_dict.items():
                test_prompt = test_prompt.replace(f'{{{key}}}', value)
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªæ›¿æ¢çš„å˜é‡
            remaining_vars = extract_variables(test_prompt)
            if remaining_vars:
                return f"âŒ ä»¥ä¸‹å˜é‡æœªå®šä¹‰: {', '.join(remaining_vars)}\n\næ›¿æ¢åçš„Prompt:\n{test_prompt}"
            else:
                return f"âœ… éªŒè¯é€šè¿‡ï¼æ‰€æœ‰å˜é‡å·²æ­£ç¡®æ›¿æ¢ã€‚\n\néªŒè¯åçš„Prompt:\n{test_prompt}"
        else:
            # æ£€æŸ¥æ˜¯å¦æœ‰å˜é‡ä½†æœªå®šä¹‰
            vars_in_prompt = extract_variables(prompt)
            if vars_in_prompt:
                return f"âš ï¸ å‘ç°æœªå®šä¹‰çš„å˜é‡: {', '.join(vars_in_prompt)}\nè¯·åœ¨å˜é‡å®šä¹‰åŒºåŸŸå®šä¹‰è¿™äº›å˜é‡ã€‚\n\nåŸå§‹Prompt:\n{prompt}"
            else:
                return f"âœ… éªŒè¯é€šè¿‡ï¼æ²¡æœ‰éœ€è¦æ›¿æ¢çš„å˜é‡ã€‚\n\nPrompt:\n{prompt}"
    
    except Exception as e:
        logger.error(f"éªŒè¯promptæ—¶å‡ºé”™: {str(e)}")
        return f"âŒ éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"

def update_variables_hint(prompt: str) -> str:
    """æ›´æ–°å˜é‡æç¤ºï¼Œå¢å¼ºç”¨æˆ·ä½“éªŒ"""
    try:
        if not prompt:
            return "è¯·å…ˆè¾“å…¥promptå†…å®¹"
            
        variables = extract_variables(prompt)
        if variables:
            hint = "å‘ç°ä»¥ä¸‹å˜é‡ï¼Œè¯·å®šä¹‰å…¶å€¼ï¼š\n"
            for var in sorted(variables):  # æ’åºä»¥ä¿æŒä¸€è‡´æ€§
                hint += f"{var}=åœ¨æ­¤è¾“å…¥{var}çš„å€¼\n"
            logger.debug(f"æ›´æ–°å˜é‡æç¤ºï¼Œå‘ç° {len(variables)} ä¸ªå˜é‡")
            return hint
        else:
            return "æœªå‘ç°å˜é‡ï¼Œå¦‚éœ€æ·»åŠ å˜é‡è¯·ä½¿ç”¨{å˜é‡å}æ ¼å¼"
    except Exception as e:
        logger.error(f"æ›´æ–°å˜é‡æç¤ºæ—¶å‡ºé”™: {str(e)}")
        return "æ›´æ–°å˜é‡æç¤ºæ—¶å‡ºç°é”™è¯¯"

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="Promptä¼˜åŒ–å™¨ - Webç•Œé¢", theme=gr.themes.Soft()) as app:
    gr.HTML("""
    <div style="text-align: center; padding: 20px;">
        <h1>ğŸ¤– Promptä¼˜åŒ–å™¨</h1>
        <p>åŸºäºå¤šAgentåä½œçš„æ™ºèƒ½Promptä¼˜åŒ–ç³»ç»Ÿ</p>
        <p>æ”¯æŒæµå¼è¾“å‡ºã€æ‰‹åŠ¨éªŒè¯å’Œå˜é‡ç¼–è¾‘</p>
    </div>
    """)
    
    with gr.Tabs() as tabs:
        with gr.Tab("ğŸš€ Promptä¼˜åŒ–", id=0):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.HTML("<h3>ğŸ“ è¾“å…¥é…ç½®</h3>")
                    
                    role_input = gr.Textbox(
                        label="ğŸ¯ ç›®æ ‡è§’è‰²",
                        placeholder="ä¾‹å¦‚: ä¸€ä¸ªä¸“ä¸šçš„Pythonè½¯ä»¶å·¥ç¨‹å¸ˆï¼Œä¸“æ³¨äºåç«¯å¼€å‘å’ŒAPIè®¾è®¡",
                        value="",
                        lines=2
                    )
                    
                    basic_requirements = gr.Textbox(
                        label="ğŸ“ åŸºæœ¬è¦æ±‚",
                        placeholder="æè¿°è¿™ä¸ªè§’è‰²éœ€è¦åšä»€ä¹ˆï¼Œä¾‹å¦‚ï¼š\n- ç¼–å†™é«˜è´¨é‡ã€å¯ç»´æŠ¤çš„Pythonä»£ç \n- è®¾è®¡RESTful API\n- å¤„ç†æ•°æ®åº“æŸ¥è¯¢å’Œä¼˜åŒ–",
                        lines=4,
                        value=""
                    )
                    
                    examples_input = gr.Textbox(
                        label="ğŸ“š ç¤ºä¾‹ (å¯é€‰)",
                        placeholder="""[
  {
    "input": {
      "function_name": "validate_email",
      "input_type": "str",
      "output_type": "bool",
      "description": "éªŒè¯é‚®ç®±åœ°å€æ ¼å¼"
    },
    "output": "def validate_email(email: str) -> bool:\\n    if not isinstance(email, str):\\n        return False\\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\\n    return bool(re.match(pattern, email))"
  },
  {
    "input": {
      "class_name": "DatabaseConnection",
      "host": "localhost",
      "database": "mydb",
      "username": "admin"
    },
    "output": "@app.route('/api/users', methods=['GET'])\\ndef get_users():\\n    return jsonify(users)"
  }
]""",
                        lines=12,
                        value=""
                    )
                    
                    additional_requirements = gr.Textbox(
                        label="â• é¢å¤–è¦æ±‚ (å¯é€‰)",
                        placeholder="è¡¥å……è¯´æ˜ç‰¹æ®Šè¦æ±‚ï¼Œä¾‹å¦‚ï¼š\n- ä»£ç éœ€è¦åŒ…å«è¯¦ç»†çš„æ³¨é‡Š\n- éœ€è¦å¤„ç†è¾¹ç•Œæƒ…å†µ\n- éœ€è¦è€ƒè™‘æ€§èƒ½ä¼˜åŒ–",
                        lines=3,
                        value=""
                    )
                    
                    model_type = gr.Dropdown(
                        label="ğŸ¤– é€‰æ‹©æ¨¡å‹",
                        choices=["gemini", "openai"],
                        value="openai",
                        info="Gemini (Google) æˆ– OpenAI GPT"
                    )
                    
                    optimize_btn = gr.Button("ğŸš€ å¼€å§‹ä¼˜åŒ–", variant="primary", size="lg")
                
                with gr.Column(scale=2):
                    gr.HTML("<h3>ğŸ“Š ä¼˜åŒ–è¿‡ç¨‹</h3>")
                    
                    status_output = gr.Textbox(
                        label="ğŸ”„ å®æ—¶çŠ¶æ€",
                        lines=10,
                        interactive=False,
                        show_copy_button=True
                    )
                    
                    with gr.Group():
                        result_output = gr.Markdown(
                            label="ğŸ“‹ ä¼˜åŒ–ç»“æœ",
                            visible=False
                        )
                        
                        with gr.Row():
                            copy_prompt_btn = gr.Button("ğŸ“‹ å¤åˆ¶æœ€ç»ˆPrompt", variant="primary", visible=False)
                            view_prompt_btn = gr.Button("ğŸ” åœ¨éªŒè¯é¡µé¢æŸ¥çœ‹", variant="secondary", visible=False)
        
        with gr.Tab("ğŸ”§ æ‰‹åŠ¨éªŒè¯", id=1):
            gr.HTML("<h3>âœ¨ PromptéªŒè¯å’Œå˜é‡ç¼–è¾‘</h3>")
            
            with gr.Row():
                with gr.Column():
                    manual_prompt = gr.Textbox(
                        label="ğŸ“ Promptå†…å®¹",
                        placeholder="è¯·å…ˆè¿è¡Œä¼˜åŒ–æˆ–æ‰‹åŠ¨è¾“å…¥prompt...",
                        lines=10,
                        show_copy_button=True
                    )
                    
                    load_prompt_btn = gr.Button("ğŸ“¥ åŠ è½½å·²ç”Ÿæˆçš„Prompt", variant="secondary")
                    
                    variables_hint = gr.Textbox(
                        label="ğŸ’¡ å˜é‡æç¤º",
                        interactive=False,
                        lines=3
                    )
                    
                    variables_input = gr.Textbox(
                        label="ğŸ”§ å˜é‡å®šä¹‰",
                        placeholder="name=å¼ ä¸‰\ntopic=äººå·¥æ™ºèƒ½\ndate=2024å¹´",
                        lines=5,
                        info="æ ¼å¼: å˜é‡å=å€¼ (æ¯è¡Œä¸€ä¸ª)"
                    )
                    
                    validate_btn = gr.Button("âœ… éªŒè¯Prompt", variant="primary")
                
                with gr.Column():
                    validation_result = gr.Markdown(
                        label="ğŸ¯ éªŒè¯ç»“æœ",
                        value="è¯·è¾“å…¥promptå¹¶ç‚¹å‡»éªŒè¯..."
                    )
        
        with gr.Tab("ğŸ“– ä½¿ç”¨è¯´æ˜", id=2):
            gr.Markdown("""
            ## ğŸ“‹ ä½¿ç”¨æŒ‡å—
            
            ### ğŸš€ åŸºæœ¬ä½¿ç”¨æµç¨‹
            1. **å¡«å†™ç›®æ ‡è§’è‰²**: æè¿°promptçš„ç›®æ ‡ç”¨æˆ·ç¾¤ä½“
            2. **é€‰æ‹©æ¨¡å‹**: Gemini (æ¨è) æˆ– OpenAI
            3. **æä¾›ç¤ºä¾‹**: è¾“å…¥æœŸæœ›çš„è¾“å…¥è¾“å‡ºç¤ºä¾‹ï¼Œä½¿ç”¨JSONæ ¼å¼å®šä¹‰å˜é‡
            4. **æ·»åŠ è¦æ±‚**: å¯é€‰çš„é¢å¤–è¦æ±‚å’Œçº¦æŸ
            5. **å¼€å§‹ä¼˜åŒ–**: ç‚¹å‡»æŒ‰é’®å¼€å§‹æµå¼ä¼˜åŒ–è¿‡ç¨‹
            
            ### ğŸ”§ ç¤ºä¾‹æ ¼å¼
            
            **JSONæ ¼å¼ (æ¨è):**
            ```json
            [
              {
                "input": {
                  "function_name": "validate_email",
                  "input_type": "str",
                  "output_type": "bool",
                  "description": "éªŒè¯é‚®ç®±åœ°å€æ ¼å¼"
                },
                "output": "def validate_email(email: str) -> bool:\\n    if not isinstance(email, str):\\n        return False\\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\\n    return bool(re.match(pattern, email))"
              }
            ]
            ```
            
            **ç®€å•æ–‡æœ¬æ ¼å¼:**
            ```
            Input:
            function_name=validate_email
            input_type=str
            output_type=bool
            description=éªŒè¯é‚®ç®±åœ°å€æ ¼å¼
            Output:
            def validate_email(email: str) -> bool:
                if not isinstance(email, str):
                    return False
                pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'
                return bool(re.match(pattern, email))
            ```
            
            ### ğŸ”§ æ‰‹åŠ¨éªŒè¯åŠŸèƒ½
            
            1. **å˜é‡æ”¯æŒ**: åœ¨promptä¸­ä½¿ç”¨ `{å˜é‡å}` å®šä¹‰åŠ¨æ€å˜é‡
            2. **å˜é‡å®šä¹‰**: åœ¨éªŒè¯é¡µé¢å®šä¹‰å˜é‡å€¼
            3. **å®æ—¶éªŒè¯**: æŸ¥çœ‹æ›¿æ¢å˜é‡åçš„æœ€ç»ˆprompt
            
            **å˜é‡å®šä¹‰ç¤ºä¾‹:**
            ```
            function_name=validate_email
            input_type=str
            output_type=bool
            description=éªŒè¯é‚®ç®±åœ°å€æ ¼å¼
            ```
            
            ### ğŸŒ ç¯å¢ƒé…ç½®
            
            éœ€è¦é…ç½®ç›¸åº”çš„APIå¯†é’¥ï¼š
            - **Gemini**: `GOOGLE_API_KEY`
            - **OpenAI**: `OPENAI_API_KEY`
            
            ### ğŸ”„ ä»£ç†è®¾ç½®
            
            ç³»ç»Ÿè‡ªåŠ¨ä½¿ç”¨ä»£ç†é…ç½® `http://127.0.0.1:7890`ï¼Œå¦‚éœ€ä¿®æ”¹è¯·è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
            ```bash
            export HTTPS_PROXY=your_proxy_url
            export HTTP_PROXY=your_proxy_url
            ```
            """)
    
    # äº‹ä»¶ç»‘å®š
    def switch_to_validation_tab():
        return gr.Tabs(selected=1), get_current_prompt()
    
    optimize_btn.click(
        fn=run_optimization,
        inputs=[role_input, basic_requirements, examples_input, additional_requirements, model_type],
        outputs=[status_output, result_output, copy_prompt_btn, view_prompt_btn],
        show_progress=True
    )
    
    copy_prompt_btn.click(
        fn=get_current_prompt,
        outputs=[gr.Textbox(visible=False)],
        js="(prompt) => navigator.clipboard.writeText(prompt)"
    )
    
    view_prompt_btn.click(
        fn=switch_to_validation_tab,
        outputs=[tabs, manual_prompt]
    )
    
    manual_prompt.change(
        fn=update_variables_hint,
        inputs=[manual_prompt],
        outputs=[variables_hint]
    )
    
    validate_btn.click(
        fn=validate_prompt,
        inputs=[manual_prompt, variables_input],
        outputs=[validation_result]
    )
    
    load_prompt_btn.click(
        fn=get_current_prompt,
        outputs=[manual_prompt]
    )

def main():
    """å¯åŠ¨Webåº”ç”¨"""
    print("ğŸš€ å¯åŠ¨Promptä¼˜åŒ–å™¨Webç•Œé¢...")
    print("ğŸŒ ä»£ç†é…ç½®: è‡ªåŠ¨ä½¿ç”¨ http://127.0.0.1:7890")
    print("ğŸ“– è®¿é—®åœ°å€: http://localhost:7860")
    
    # æ£€æŸ¥ç¯å¢ƒ
    google_api_key = os.getenv('GOOGLE_API_KEY')
    openai_api_key = os.getenv('OPENAI_API_KEY')
    
    print("\nğŸ”‘ APIå¯†é’¥çŠ¶æ€:")
    print(f"   Google (Gemini): {'âœ… å·²é…ç½®' if google_api_key and google_api_key != 'your_google_api_key_here' else 'âŒ æœªé…ç½®'}")
    print(f"   OpenAI (GPT): {'âœ… å·²é…ç½®' if openai_api_key and openai_api_key != 'your_openai_api_key_here' else 'âŒ æœªé…ç½®'}")
    
    print("\nğŸ’¡ æç¤º: è¯·ç¡®ä¿è‡³å°‘é…ç½®ä¸€ä¸ªAPIå¯†é’¥ä»¥ä½¿ç”¨ç›¸åº”çš„æ¨¡å‹")
    
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )

if __name__ == "__main__":
    main() 